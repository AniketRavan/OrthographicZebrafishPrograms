{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2751be46-8f63-4b28-b298-854ecb1446a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import cv2 as cv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "#from programs.ResNet_Blocks_3D_four_blocks_test import resnet18\n",
    "from programs.ResNet_Blocks_3D_four_blocks import resnet18\n",
    "from programs.CustomDataset2 import CustomImageDataset\n",
    "from programs.CustomDataset2 import padding\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9b91087-7605-43e3-b31b-e63d8dad0104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bgsubList(folderName, filenames):\n",
    "\n",
    "    frames = []\n",
    "    for filename in filenames:\n",
    "        frame = cv2.imread(folderName + '/' + filename)\n",
    "        grayImage = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frames.append(grayImage)\n",
    "\n",
    "    frameCount = len(frames)\n",
    "    nSampFrame = min(np.fix(frameCount / 2), 100)\n",
    "\n",
    "    # Creating a numpy array of the the sample frames\n",
    "    firstSampFrame = True\n",
    "    secondSampFrame = True\n",
    "    for frameNum in np.fix(np.linspace(1, frameCount, int(nSampFrame))):\n",
    "        if firstSampFrame:\n",
    "            firstSampFrame = False\n",
    "            sampFrames = frames[0]\n",
    "            continue\n",
    "        if secondSampFrame:\n",
    "            secondSampFrame = False\n",
    "            sampFrames = np.stack((sampFrames, frames[int((frameNum - 1))]), axis=0)\n",
    "            continue\n",
    "        sampFrames = np.vstack((sampFrames, np.array([frames[int((frameNum - 1))]])))\n",
    "\n",
    "    sampFrames.sort(0)\n",
    "\n",
    "    videobg = sampFrames[int(np.fix(nSampFrame * .9))]\n",
    "\n",
    "    outputVid = []\n",
    "    for frame in frames:\n",
    "        # Subtract foreground from background image by allowing values beyond the 0 to 255 range of uint8\n",
    "        difference_img = np.int16(videobg) - np.int16(frame)\n",
    "\n",
    "        # Clip values in [0,255] range\n",
    "        difference_img = np.clip(difference_img, 0, 255)\n",
    "\n",
    "        # Convert difference image to uint8 for saving to video\n",
    "        difference_img = np.uint8(difference_img)\n",
    "        outputVid.append(difference_img)\n",
    "\n",
    "    return outputVid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d471201-e822-46e7-91f9-40a119e35954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isBoxFarFromEdge(box):\n",
    "    edgeThreshold = 5\n",
    "    imageSizeX, imageSizeY = 640, 640\n",
    "    xDistance = np.min(imageSizeX - box[[0,2]])\n",
    "    xDistance2 = np.min(box[[0,2]])\n",
    "    xDistanceMin = min(xDistance, xDistance2)\n",
    "    yDistance = np.min(imageSizeY - box[[1,3]])\n",
    "    yDistance2 = np.min(box[[1,3]])\n",
    "    yDistanceMin = min(yDistance, yDistance2)\n",
    "    minDist = min(yDistanceMin, xDistanceMin)\n",
    "    \n",
    "    return minDist > edgeThreshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "440670ce-9eee-4193-9a0d-ab966ff10bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bgsub done\n"
     ]
    }
   ],
   "source": [
    "folder = '020116_012/'\n",
    "files = os.listdir(folder)\n",
    "files = [fileName for fileName in files if fileName.endswith('.bmp')]\n",
    "files.sort()\n",
    "\n",
    "bgsubIms = bgsubList(folder[:-1], files)\n",
    "\n",
    "#im0 = cv.imread(folder + files[0])\n",
    "im0 = bgsubIms[0]\n",
    "print('bgsub done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "878cd60d-effc-4ff7-afc0-97a93813b0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "yoloWeigths = 'inputs/weights/orthographic_yolo/best.pt'\n",
    "\n",
    "model = YOLO(yoloWeigths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd8d5503-ed4b-4997-b264-de863d2b34f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawBox(im, box):\n",
    "    red = [0,0,255]\n",
    "    box = np.copy(box)\n",
    "    box = box.astype(int)\n",
    "    sx, sy, bx, by = box\n",
    "    im[sy,sx:bx + 1] = red\n",
    "    im[by,sx:bx + 1] = red\n",
    "    im[sy:by + 1, sx] = red\n",
    "    im[sy:by + 1, bx] = red\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dfa3cfc-65af-473e-8859-49e91cd990bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4977/4977 [01:40<00:00, 58.97it/s]"
     ]
    }
   ],
   "source": [
    "imageSizeX, imageSizeY = 640, 640\n",
    "fps = 500\n",
    "#fps = cap.get( cv.CAP_PROP_FPS )\n",
    "fourcc = cv.VideoWriter_fourcc('M','J','P','G')\n",
    "#fourcc = cv.VideoWriter_fourcc(*'DIVX')\n",
    "#outputPath = 'outputs/superimposed/' + videoName + '.avi'\n",
    "outputPath = 'yoloVideo.avi'\n",
    "out = cv.VideoWriter(outputPath, fourcc  , int( fps  ) ,(int(imageSizeX) , int( imageSizeY )))\n",
    "\n",
    "#confidence_mask = result.boxes.conf.cpu().numpy() > .5\n",
    "#boxList = result.boxes.xyxy.cpu().numpy()[confidence_mask]\n",
    "#keypointsList = result.keypoints.xy.cpu().numpy()[confidence_mask]\n",
    "#mask = [isBoxFarFromEdge(box) for box in boxList]\n",
    "#boxList = boxList[mask]\n",
    "#keypointsList = keypointsList[mask]\n",
    "bar = tqdm(total = len(bgsubIms))\n",
    "\n",
    "batchsize = 500\n",
    "fc = 0\n",
    "frames = []\n",
    "amountOfFrames = len(bgsubIms)\n",
    "while True:\n",
    "    frame = bgsubIms[fc]\n",
    "    fc += 1\n",
    "    frame = np.stack((frame, frame, frame), axis = 2)\n",
    "    frame = frame.astype(float)\n",
    "    frame *= 255 / np.max(frame)\n",
    "    frame = frame.astype(np.uint8)\n",
    "    \n",
    "    frames.append(frame)\n",
    "    \n",
    "    if len(frames) >= batchsize or fc >= amountOfFrames:\n",
    "        results = model(frames, verbose = False)\n",
    "        masterBoxList = []\n",
    "        for result in results:\n",
    "            confidence_mask = result.boxes.conf.cpu().numpy() > .5\n",
    "            boxList = result.boxes.xyxy.cpu().numpy()[confidence_mask]\n",
    "            mask = [isBoxFarFromEdge(box) for box in boxList]\n",
    "            boxList = boxList[mask]\n",
    "            masterBoxList.append(boxList)\n",
    "        \n",
    "        \n",
    "        for frameIdx, _ in enumerate(frames):\n",
    "            realFrameIdx = (fc - len(frames)) + frameIdx\n",
    "            gray = bgsubIms[realFrameIdx]\n",
    "            rgb = np.stack((gray,gray,gray), axis = 2)\n",
    "            boxList = masterBoxList[frameIdx]\n",
    "            for box in boxList:\n",
    "                rgb = drawBox(rgb, box)\n",
    "            \n",
    "            out.write(rgb)\n",
    "        bar.update(len(frames))\n",
    "        frames = []\n",
    "    if fc >= amountOfFrames: break\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03684e4a-efb3-46e7-ad51-ebb3e4b6a5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4977\n"
     ]
    }
   ],
   "source": [
    "print(fc)\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14c2f95e-427c-4d9a-88e6-c7f8fdb21a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4977/4977 [01:10<00:00, 109.09it/s]"
     ]
    }
   ],
   "source": [
    "imageSizeX, imageSizeY = 640, 640\n",
    "\n",
    "dataList = []\n",
    "#confidence_mask = result.boxes.conf.cpu().numpy() > .5\n",
    "#boxList = result.boxes.xyxy.cpu().numpy()[confidence_mask]\n",
    "#keypointsList = result.keypoints.xy.cpu().numpy()[confidence_mask]\n",
    "#mask = [isBoxFarFromEdge(box) for box in boxList]\n",
    "#boxList = boxList[mask]\n",
    "#keypointsList = keypointsList[mask]\n",
    "bar = tqdm(total = len(bgsubIms))\n",
    "\n",
    "batchsize = 500\n",
    "fc = 0\n",
    "frames = []\n",
    "amountOfFrames = len(bgsubIms)\n",
    "while True:\n",
    "    frame = bgsubIms[fc]\n",
    "    fc += 1\n",
    "    frame = np.stack((frame, frame, frame), axis = 2)\n",
    "    frame = frame.astype(float)\n",
    "    frame *= 255 / np.max(frame)\n",
    "    frame = frame.astype(np.uint8)\n",
    "    \n",
    "    frames.append(frame)\n",
    "    \n",
    "    if len(frames) >= batchsize or fc >= amountOfFrames:\n",
    "        results = model(frames, verbose = False)\n",
    "        masterBoxList = []\n",
    "        for result in results:\n",
    "            confidence_mask = result.boxes.conf.cpu().numpy() > .7\n",
    "            classes = result.boxes.cls.cpu().numpy()[confidence_mask]\n",
    "            boxList = result.boxes.xyxy.cpu().numpy()[confidence_mask]\n",
    "            keypointsList = result.keypoints.xy.cpu().numpy()[confidence_mask]\n",
    "            \n",
    "            mask = [isBoxFarFromEdge(box) for box in boxList]\n",
    "            boxList = boxList[mask]\n",
    "            keypointsList = keypointsList[mask]\n",
    "            classes = classes[mask]\n",
    "            \n",
    "            data = [classes, boxList, keypointsList]\n",
    "            dataList.append(data)\n",
    "            \n",
    "        bar.update(len(frames))\n",
    "        frames = []\n",
    "    if fc >= amountOfFrames: break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1a7f230-ce4c-404e-a2a7-e2ccc2ac3d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('orthographicVideoYoloData.pkl', 'wb') as b:\n",
    "    pickle.dump(dataList, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1771a030-1eb0-4afa-a226-0ab330104ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:opence-v1.5.1]",
   "language": "python",
   "name": "conda-env-opence-v1.5.1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
